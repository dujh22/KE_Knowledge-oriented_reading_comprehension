{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bignet/anaconda3/envs/knowledgeEngineer/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集\n",
    "from paddlenlp.datasets import load_dataset\n",
    "# 飞桨的NLP库\n",
    "import paddlenlp as ppnlp\n",
    "# 数据预处理\n",
    "from utils.utils import prepare_train_features, prepare_validation_features\n",
    "# 偏函数应用\n",
    "from functools import partial\n",
    "# 评估SQuAD任务\n",
    "from paddlenlp.metrics.squad import squad_evaluate, compute_prediction\n",
    "# 集合类\n",
    "import collections\n",
    "# 操作时间的函数\n",
    "import time\n",
    "# 理JSON数据\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "仙剑奇侠传3第几集上天界\n",
      "第35集雪见缓缓张开眼睛，景天又惊又喜之际，长卿和紫萱的仙船驶至，见众人无恙，也十分高兴。众人登船，用尽合力把自身的真气和水分输给她。雪见终于醒过来了，但却一脸木然，全无反应。众人向常胤求助，却发现人世界竟没有雪见的身世纪录。长卿询问清微的身世，清微语带双关说一切上了天界便有答案。长卿驾驶仙船，众人决定立马动身，往天界而去。众人来到一荒山，长卿指出，魔界和天界相连。由魔界进入通过神魔之井，便可登天。众人至魔界入口，仿若一黑色的蝙蝠洞，但始终无法进入。后来花楹发现只要有翅膀便能飞入。于是景天等人打下许多乌鸦，模仿重楼的翅膀，制作数对翅膀状巨物。刚佩戴在身，便被吸入洞口。众人摔落在地，抬头发现魔界守卫。景天和众魔套交情，自称和魔尊重楼相熟，众魔不理，打了起来。\n",
      "['第35集']\n",
      "[0]\n",
      "\n",
      "燃气热水器哪个牌子好\n",
      "选择燃气热水器时，一定要关注这几个问题：1、出水稳定性要好，不能出现忽热忽冷的现象2、快速到达设定的需求水温3、操作要智能、方便4、安全性要好，要装有安全报警装置 市场上燃气热水器品牌众多，购买时还需多加对比和仔细鉴别。方太今年主打的磁化恒温热水器在使用体验方面做了全面升级：9秒速热，可快速进入洗浴模式；水温持久稳定，不会出现忽热忽冷的现象，并通过水量伺服技术将出水温度精确控制在±0.5℃，可满足家里宝贝敏感肌肤洗护需求；配备CO和CH4双气体报警装置更安全（市场上一般多为CO单气体报警）。另外，这款热水器还有智能WIFI互联功能，只需下载个手机APP即可用手机远程操作热水器，实现精准调节水温，满足家人多样化的洗浴需求。当然方太的磁化恒温系列主要的是增加磁化功能，可以有效吸附水中的铁锈、铁屑等微小杂质，防止细菌滋生，使沐浴水质更洁净，长期使用磁化水沐浴更利于身体健康。\n",
      "['方太']\n",
      "[110]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载dureader_robust数据集的训练集和验证集\n",
    "train_ds, dev_ds = ppnlp.datasets.load_dataset('dureader_robust', splits=('train', 'dev'))\n",
    "\n",
    "# 循环打印前两个训练样本的相关信息\n",
    "for idx in range(2):\n",
    "    # 打印问题\n",
    "    print(train_ds[idx]['question'])\n",
    "    # 打印问题的上下文\n",
    "    print(train_ds[idx]['context'])\n",
    "    # 打印问题的答案\n",
    "    print(train_ds[idx]['answers'])\n",
    "    # 打印答案在上下文中的开始位置\n",
    "    print(train_ds[idx]['answer_starts'])\n",
    "    # 打印一个空行，为了在控制台输出中区分各个样本\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-25 12:24:58,291] [    INFO]\u001B[0m - Already cached /home/bignet/.paddlenlp/models/bert-base-chinese/bert-base-chinese-vocab.txt\u001B[0m\n",
      "\u001B[32m[2023-06-25 12:24:58,298] [    INFO]\u001B[0m - tokenizer config file saved in /home/bignet/.paddlenlp/models/bert-base-chinese/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-25 12:24:58,298] [    INFO]\u001B[0m - Special tokens file saved in /home/bignet/.paddlenlp/models/bert-base-chinese/special_tokens_map.json\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# 设置模型名称\n",
    "MODEL_NAME = \"bert-base-chinese\"\n",
    "# 使用指定模型名称初始化tokenizer\n",
    "tokenizer = ppnlp.transformers.BertTokenizer.from_pretrained(MODEL_NAME)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<paddlenlp.datasets.dataset.MapDataset at 0x7fa09e117f10>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置最大序列长度\n",
    "max_seq_length = 512\n",
    "# 设置文档滑动窗口的步长\n",
    "doc_stride = 128\n",
    "\n",
    "# 创建训练集转换函数，使用部分参数和tokenizer\n",
    "train_trans_func = partial(prepare_train_features,\n",
    "                           max_seq_length=max_seq_length,\n",
    "                           doc_stride=doc_stride,\n",
    "                           tokenizer=tokenizer)\n",
    "\n",
    "# 对训练集进行转换，并进行批处理\n",
    "train_ds.map(train_trans_func, batched=True)\n",
    "\n",
    "# 创建验证集转换函数，使用部分参数和tokenizer\n",
    "dev_trans_func = partial(prepare_validation_features,\n",
    "                         max_seq_length=max_seq_length,\n",
    "                         doc_stride=doc_stride,\n",
    "                         tokenizer=tokenizer)\n",
    "\n",
    "# 对验证集进行转换，并进行批处理\n",
    "dev_ds.map(dev_trans_func, batched=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 7391, 5966, 2466, 6121, 6756, 6381, 2497, 811, 1525, 702, 4277, 2094, 1962, 102, 2972, 5773, 886, 4500, 8286, 6121, 6756, 6381, 2497, 811, 511, 6121, 6756, 6381, 2497, 811, 4638, 1962, 1776, 8024, 1357, 1104, 754, 6121, 6756, 6381, 2497, 811, 4638, 3029, 1008, 1928, 6981, 5390, 8024, 6981, 5390, 6632, 7770, 6632, 1962, 8024, 1086, 2218, 3221, 2595, 817, 3683, 511, 6121, 6756, 6381, 2497, 811, 6981, 5390, 7444, 6206, 8990, 8158, 8187, 6631, 7770, 3926, 3029, 1008, 1928, 3683, 6772, 1962, 8024, 6821, 3416, 2497, 1169, 6228, 7574, 3926, 3251, 2428, 7770, 511, 1086, 2218, 3221, 817, 3419, 8024, 2595, 817, 3683, 7770, 738, 3221, 1377, 809, 966, 2533, 5440, 5991, 4638, 511, 8286, 6121, 6756, 6381, 2497, 811, 2769, 886, 4500, 749, 671, 3667, 3198, 7313, 8024, 6230, 2533, 8286, 6121, 6756, 6381, 2497, 811, 3683, 6772, 1962, 2497, 2533, 2408, 6235, 3683, 6772, 1920, 8024, 2400, 684, 912, 2139, 2141, 2669, 8024, 817, 3419, 2798, 9600, 8024, 1762, 8286, 1555, 1814, 1377, 809, 743, 1168, 511, 1377, 809, 1346, 5440, 2190, 3683, 678, 511, 102]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "14519\n",
      "[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (27, 28), (28, 29), (29, 30), (30, 31), (31, 32), (32, 33), (33, 34), (34, 35), (35, 36), (36, 37), (37, 38), (38, 39), (39, 40), (40, 41), (41, 42), (42, 43), (43, 44), (44, 45), (45, 46), (46, 47), (47, 48), (48, 49), (49, 50), (50, 51), (52, 53), (53, 54), (54, 55), (55, 56), (56, 57), (57, 58), (58, 59), (59, 60), (60, 61), (61, 64), (64, 65), (65, 66), (66, 67), (67, 68), (68, 69), (69, 70), (70, 71), (71, 72), (72, 73), (73, 74), (74, 75), (75, 76), (76, 77), (77, 78), (78, 79), (79, 80), (80, 81), (81, 82), (82, 83), (83, 84), (84, 85), (85, 86), (86, 87), (87, 88), (88, 89), (89, 90), (90, 91), (91, 92), (92, 93), (93, 94), (94, 95), (95, 96), (96, 97), (97, 98), (98, 99), (99, 100), (100, 101), (101, 102), (102, 103), (103, 104), (104, 105), (105, 106), (106, 107), (108, 111), (111, 112), (112, 113), (113, 114), (114, 115), (115, 116), (116, 117), (117, 118), (118, 119), (119, 120), (120, 121), (121, 122), (122, 123), (123, 124), (125, 126), (126, 127), (127, 128), (128, 131), (131, 132), (132, 133), (133, 134), (134, 135), (135, 136), (136, 137), (137, 138), (138, 139), (139, 140), (140, 141), (141, 142), (142, 143), (143, 144), (144, 145), (145, 146), (146, 147), (147, 148), (148, 149), (149, 150), (150, 151), (151, 152), (152, 153), (154, 155), (155, 156), (156, 157), (157, 158), (158, 161), (161, 162), (162, 163), (163, 166), (166, 167), (167, 168), (168, 169), (169, 170), (170, 171), (171, 172), (172, 173), (173, 174), (174, 175), (175, 176), (176, 177), (177, 178), (178, 179), (179, 180), (180, 181), (0, 0)]\n",
      "19\n",
      "24\n",
      "\n",
      "[101, 7391, 5966, 2466, 6121, 6756, 6381, 2497, 811, 1525, 702, 4277, 2094, 1962, 102, 2972, 5773, 886, 4500, 8286, 6121, 6756, 6381, 2497, 811, 511, 6121, 6756, 6381, 2497, 811, 4638, 1962, 1776, 8024, 1357, 1104, 754, 6121, 6756, 6381, 2497, 811, 4638, 3029, 1008, 1928, 6981, 5390, 8024, 6981, 5390, 6632, 7770, 6632, 1962, 8024, 1086, 2218, 3221, 2595, 817, 3683, 511, 6121, 6756, 6381, 2497, 811, 6981, 5390, 7444, 6206, 8990, 8158, 8187, 6631, 7770, 3926, 3029, 1008, 1928, 3683, 6772, 1962, 8024, 6821, 3416, 2497, 1169, 6228, 7574, 3926, 3251, 2428, 7770, 511, 1086, 2218, 3221, 817, 3419, 8024, 2595, 817, 3683, 7770, 738, 3221, 1377, 809, 966, 2533, 5440, 5991, 4638, 511, 8286, 6121, 6756, 6381, 2497, 811, 2769, 886, 4500, 749, 671, 3667, 3198, 7313, 8024, 6230, 2533, 8286, 6121, 6756, 6381, 2497, 811, 3683, 6772, 1962, 2497, 2533, 2408, 6235, 3683, 6772, 1920, 8024, 2400, 684, 912, 2139, 2141, 2669, 8024, 817, 3419, 2798, 9600, 8024, 1762, 8286, 1555, 1814, 1377, 809, 743, 1168, 511, 1377, 809, 1346, 5440, 2190, 3683, 678, 511, 102]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "14519\n",
      "[(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (27, 28), (28, 29), (29, 30), (30, 31), (31, 32), (32, 33), (33, 34), (34, 35), (35, 36), (36, 37), (37, 38), (38, 39), (39, 40), (40, 41), (41, 42), (42, 43), (43, 44), (44, 45), (45, 46), (46, 47), (47, 48), (48, 49), (49, 50), (50, 51), (52, 53), (53, 54), (54, 55), (55, 56), (56, 57), (57, 58), (58, 59), (59, 60), (60, 61), (61, 64), (64, 65), (65, 66), (66, 67), (67, 68), (68, 69), (69, 70), (70, 71), (71, 72), (72, 73), (73, 74), (74, 75), (75, 76), (76, 77), (77, 78), (78, 79), (79, 80), (80, 81), (81, 82), (82, 83), (83, 84), (84, 85), (85, 86), (86, 87), (87, 88), (88, 89), (89, 90), (90, 91), (91, 92), (92, 93), (93, 94), (94, 95), (95, 96), (96, 97), (97, 98), (98, 99), (99, 100), (100, 101), (101, 102), (102, 103), (103, 104), (104, 105), (105, 106), (106, 107), (108, 111), (111, 112), (112, 113), (113, 114), (114, 115), (115, 116), (116, 117), (117, 118), (118, 119), (119, 120), (120, 121), (121, 122), (122, 123), (123, 124), (125, 126), (126, 127), (127, 128), (128, 131), (131, 132), (132, 133), (133, 134), (134, 135), (135, 136), (136, 137), (137, 138), (138, 139), (139, 140), (140, 141), (141, 142), (142, 143), (143, 144), (144, 145), (145, 146), (146, 147), (147, 148), (148, 149), (149, 150), (150, 151), (151, 152), (152, 153), (154, 155), (155, 156), (156, 157), (157, 158), (158, 161), (161, 162), (162, 163), (163, 166), (166, 167), (167, 168), (168, 169), (169, 170), (170, 171), (171, 172), (172, 173), (173, 174), (174, 175), (175, 176), (176, 177), (177, 178), (178, 179), (179, 180), (180, 181), (0, 0)]\n",
      "19\n",
      "24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 对于每个索引进行循环两次\n",
    "for idx in range(2):\n",
    "    # 打印训练集中的input_ids\n",
    "    print(train_ds[idx]['input_ids'])\n",
    "    # 打印训练集中的token_type_ids\n",
    "    print(train_ds[idx]['token_type_ids'])\n",
    "    # 打印训练集中的overflow_to_sample\n",
    "    print(train_ds[idx]['overflow_to_sample'])\n",
    "    # 打印训练集中的offset_mapping\n",
    "    print(train_ds[idx]['offset_mapping'])\n",
    "    # 打印训练集中的start_positions\n",
    "    print(train_ds[idx]['start_positions'])\n",
    "    # 打印训练集中的end_positions\n",
    "    print(train_ds[idx]['end_positions'])\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddlenlp.data import Stack, Dict, Pad\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# 创建训练集的分布式批量采样器\n",
    "train_batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "    train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 定义训练集的批处理函数\n",
    "train_batchify_fn = lambda samples, fn=Dict({\n",
    "    \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id),\n",
    "    \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\n",
    "    \"start_positions\": Stack(dtype=\"int64\"),\n",
    "    \"end_positions\": Stack(dtype=\"int64\")\n",
    "}): fn(samples)\n",
    "\n",
    "# 创建训练集的数据加载器\n",
    "train_data_loader = paddle.io.DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_sampler=train_batch_sampler,\n",
    "    collate_fn=train_batchify_fn,\n",
    "    return_list=True)\n",
    "\n",
    "# 创建验证集的批采样器\n",
    "dev_batch_sampler = paddle.io.BatchSampler(\n",
    "    dev_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 定义验证集的批处理函数\n",
    "dev_batchify_fn = lambda samples, fn=Dict({\n",
    "    \"input_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_id),\n",
    "    \"token_type_ids\": Pad(axis=0, pad_val=tokenizer.pad_token_type_id)\n",
    "}): fn(samples)\n",
    "\n",
    "# 创建验证集的数据加载器\n",
    "dev_data_loader = paddle.io.DataLoader(\n",
    "    dataset=dev_ds,\n",
    "    batch_sampler=dev_batch_sampler,\n",
    "    collate_fn=dev_batchify_fn,\n",
    "    return_list=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[8, 181], dtype=int64, place=Place(gpu_pinned), stop_gradient=True,\n",
      "       [[101 , 7391, 5966, ..., 678 , 511 , 102 ],\n",
      "        [101 , 7391, 5966, ..., 678 , 511 , 102 ],\n",
      "        [101 , 7391, 5966, ..., 678 , 511 , 102 ],\n",
      "        ...,\n",
      "        [101 , 7391, 5966, ..., 678 , 511 , 102 ],\n",
      "        [101 , 7391, 5966, ..., 678 , 511 , 102 ],\n",
      "        [101 , 7391, 5966, ..., 678 , 511 , 102 ]])\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(train_data_loader, start=1):\n",
    "\n",
    "        input_ids, segment_ids, start_positions, end_positions = batch\n",
    "        print(input_ids)\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-25 12:25:56,610] [    INFO]\u001B[0m - Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"fuse\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"paddlenlp_version\": null,\n",
      "  \"pool_act\": \"tanh\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\u001B[0m\n",
      "W0625 12:25:56.854789 13446 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.0, Runtime API Version: 11.7\n",
      "W0625 12:25:56.869946 13446 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.\n",
      "\u001B[33m[2023-06-25 12:25:57,158] [ WARNING]\u001B[0m - Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForQuestionAnswering: ['cls.predictions.decoder_bias', 'cls.predictions.transform.weight', 'cls.predictions.layer_norm.bias', 'cls.predictions.transform.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder_weight', 'cls.predictions.layer_norm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001B[0m\n",
      "\u001B[33m[2023-06-25 12:25:57,158] [ WARNING]\u001B[0m - Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# 设置想要使用模型的名称\n",
    "model = ppnlp.transformers.BertForQuestionAnswering.from_pretrained(MODEL_NAME)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 训练过程中的最大学习率\n",
    "learning_rate = 3e-5\n",
    "# 训练轮次\n",
    "epochs = 1\n",
    "# 学习率预热比例\n",
    "warmup_proportion = 0.1\n",
    "# 权重衰减系数，类似模型正则项策略，避免模型过拟合\n",
    "weight_decay = 0.01\n",
    "\n",
    "# 计算总的训练步数\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "\n",
    "# 创建学习率调度器，使用线性衰减和预热\n",
    "lr_scheduler = ppnlp.transformers.LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)\n",
    "\n",
    "# 生成需要进行权重衰减的参数名称列表，排除所有bias和LayerNorm参数\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "\n",
    "# 创建AdamW优化器，设置学习率、参数和权重衰减\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=weight_decay,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class CrossEntropyLossForSQuAD(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLossForSQuAD, self).__init__()\n",
    "\n",
    "    def forward(self, y, label):\n",
    "        start_logits, end_logits = y   # both shape are [batch_size, seq_len]\n",
    "        start_position, end_position = label\n",
    "        start_position = paddle.unsqueeze(start_position, axis=-1)\n",
    "        end_position = paddle.unsqueeze(end_position, axis=-1)\n",
    "\n",
    "        # 计算起始位置的损失\n",
    "        start_loss = paddle.nn.functional.softmax_with_cross_entropy(\n",
    "            logits=start_logits, label=start_position, soft_label=False)\n",
    "        start_loss = paddle.mean(start_loss)\n",
    "\n",
    "        # 计算结束位置的损失\n",
    "        end_loss = paddle.nn.functional.softmax_with_cross_entropy(\n",
    "            logits=end_logits, label=end_position, soft_label=False)\n",
    "        end_loss = paddle.mean(end_loss)\n",
    "\n",
    "        # 求平均损失\n",
    "        loss = (start_loss + end_loss) / 2\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 100, epoch: 1, batch: 100, loss: 0.00001\n",
      "global step 200, epoch: 1, batch: 200, loss: 0.00001\n",
      "global step 300, epoch: 1, batch: 300, loss: 0.00001\n",
      "global step 400, epoch: 1, batch: 400, loss: 0.00001\n",
      "global step 500, epoch: 1, batch: 500, loss: 0.00001\n",
      "global step 600, epoch: 1, batch: 600, loss: 0.00001\n",
      "global step 700, epoch: 1, batch: 700, loss: 0.00001\n",
      "global step 800, epoch: 1, batch: 800, loss: 0.00001\n",
      "global step 900, epoch: 1, batch: 900, loss: 0.00001\n",
      "global step 1000, epoch: 1, batch: 1000, loss: 0.00001\n",
      "global step 1100, epoch: 1, batch: 1100, loss: 0.00001\n",
      "global step 1200, epoch: 1, batch: 1200, loss: 0.00001\n",
      "global step 1300, epoch: 1, batch: 1300, loss: 0.00001\n",
      "global step 1400, epoch: 1, batch: 1400, loss: 0.00001\n",
      "global step 1500, epoch: 1, batch: 1500, loss: 0.00001\n",
      "global step 1600, epoch: 1, batch: 1600, loss: 0.00001\n",
      "global step 1700, epoch: 1, batch: 1700, loss: 0.00001\n",
      "global step 1800, epoch: 1, batch: 1800, loss: 0.00001\n",
      "global step 1900, epoch: 1, batch: 1900, loss: 0.00001\n",
      "global step 2000, epoch: 1, batch: 2000, loss: 0.00001\n",
      "global step 2100, epoch: 1, batch: 2100, loss: 0.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-25 13:07:28,223] [    INFO]\u001B[0m - Configuration saved in ./checkpoint/config.json\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2200, epoch: 1, batch: 2200, loss: 0.00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-06-25 13:07:28,642] [    INFO]\u001B[0m - tokenizer config file saved in ./checkpoint/tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2023-06-25 13:07:28,643] [    INFO]\u001B[0m - Special tokens file saved in ./checkpoint/special_tokens_map.json\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "('./checkpoint/tokenizer_config.json',\n './checkpoint/special_tokens_map.json',\n './checkpoint/added_tokens.json')"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 3e-5\n",
    "from utils.utils import evaluate\n",
    "\n",
    "criterion = CrossEntropyLossForSQuAD()\n",
    "global_step = 0\n",
    "\n",
    "# 遍历每个训练轮次\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # 遍历训练集中的每个批次数据\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        global_step += 1\n",
    "        input_ids, segment_ids, start_positions, end_positions = batch\n",
    "        logits = model(input_ids=input_ids, token_type_ids=segment_ids)\n",
    "        loss = criterion(logits, (start_positions, end_positions))\n",
    "\n",
    "        if global_step % 100 == 0:\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f\" % (global_step, epoch, step, loss))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "\n",
    "    # # 在每个轮次结束后进行验证集评估\n",
    "    # evaluate(model=model, data_loader=dev_data_loader)\n",
    "\n",
    "# 保存模型和tokenizer\n",
    "model.save_pretrained('./checkpoint')\n",
    "tokenizer.save_pretrained('./checkpoint')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<paddle.fluid.reader.DataLoader object at 0x7fa09d9a1b20>\n",
      "Processing example: 1000\n",
      "time per 1000: 57.42130756378174\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m evaluate\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# 在每个轮次结束后进行验证集评估\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdev_data_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/knowledgeEngineer/lib/python3.8/site-packages/decorator.py:232\u001B[0m, in \u001B[0;36mdecorate.<locals>.fun\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwsyntax:\n\u001B[1;32m    231\u001B[0m     args, kw \u001B[38;5;241m=\u001B[39m fix(args, kw, sig)\n\u001B[0;32m--> 232\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcaller\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mextras\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/knowledgeEngineer/lib/python3.8/site-packages/paddle/fluid/dygraph/base.py:375\u001B[0m, in \u001B[0;36mno_grad_.__call__.<locals>._decorate_function\u001B[0;34m(func, *args, **kwargs)\u001B[0m\n\u001B[1;32m    372\u001B[0m \u001B[38;5;129m@decorator\u001B[39m\u001B[38;5;241m.\u001B[39mdecorator\n\u001B[1;32m    373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_decorate_function\u001B[39m(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    374\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 375\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/knowledgeEngineer/utils/utils.py:49\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(model, data_loader, is_test)\u001B[0m\n\u001B[1;32m     46\u001B[0m         all_end_logits\u001B[38;5;241m.\u001B[39mappend(end_logits_tensor\u001B[38;5;241m.\u001B[39mnumpy()[idx])\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# 使用预测结果生成最终的答案\u001B[39;00m\n\u001B[0;32m---> 49\u001B[0m all_predictions, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_prediction\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_start_logits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_end_logits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;66;03m# 如果是测试阶段\u001B[39;00m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_test:\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;66;03m# 将预测结果写入JSON文件中\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/knowledgeEngineer/lib/python3.8/site-packages/paddlenlp/metrics/squad.py:72\u001B[0m, in \u001B[0;36mcompute_prediction\u001B[0;34m(examples, features, predictions, version_2_with_negative, n_best_size, max_answer_length, null_score_diff_threshold)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(predictions[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(features), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of predictions should be equal to number of features.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# Build a map example to its corresponding features.\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m example_id_to_index \u001B[38;5;241m=\u001B[39m {k: i \u001B[38;5;28;01mfor\u001B[39;00m i, k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[43mexamples\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m)}\n\u001B[1;32m     73\u001B[0m features_per_example \u001B[38;5;241m=\u001B[39m collections\u001B[38;5;241m.\u001B[39mdefaultdict(\u001B[38;5;28mlist\u001B[39m)\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, feature \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(features):\n",
      "\u001B[0;31mTypeError\u001B[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from utils.utils import evaluate\n",
    "# 在每个轮次结束后进行验证集评估\n",
    "evaluate(model=model, data_loader=dev_data_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing example: 1000\n",
      "time per 1000: 3.9928367137908936\n",
      "{'id': 'f1aafd23e0e12281770401586c8a4710', 'title': '', 'context': '爬行垫根据中间材料的不同可以分为:XPE爬行垫、EPE爬行垫、EVA爬行垫、PVC爬行垫;其中XPE爬行垫、EPE爬行垫都属于PE材料加保鲜膜复合而成,都是无异味的环保材料,但是XPE爬行垫是品质较好的爬行垫,韩国进口爬行垫都是这种爬行垫,而EPE爬行垫是国内厂家为了减低成本,使用EPE(珍珠棉)作为原料生产的一款爬行垫,该材料弹性差,易碎,开孔发泡防水性弱。EVA爬行垫、PVC爬行垫是用EVA或PVC作为原材料与保鲜膜复合的而成的爬行垫,或者把图案转印在原材料上,这两款爬行垫通常有异味,如果是图案转印的爬行垫,油墨外露容易脱落。 当时我儿子爬的时候,我们也买了垫子,但是始终有味。最后就没用了,铺的就的薄毯子让他爬。', 'question': '爬行垫什么材质的好', 'answers': ['XPE'], 'answer_starts': [-1]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 46\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28mprint\u001B[39m(data_loader\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39mdata[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# 使用预测结果生成最终的答案\u001B[39;00m\n\u001B[0;32m---> 46\u001B[0m all_predictions, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_prediction\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnew_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_start_logits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_end_logits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m# 如果是测试阶段\u001B[39;00m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_test:\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;66;03m# 将预测结果写入JSON文件中\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/knowledgeEngineer/lib/python3.8/site-packages/paddlenlp/metrics/squad.py:72\u001B[0m, in \u001B[0;36mcompute_prediction\u001B[0;34m(examples, features, predictions, version_2_with_negative, n_best_size, max_answer_length, null_score_diff_threshold)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(predictions[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(features), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of predictions should be equal to number of features.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# Build a map example to its corresponding features.\u001B[39;00m\n\u001B[0;32m---> 72\u001B[0m example_id_to_index \u001B[38;5;241m=\u001B[39m {k: i \u001B[38;5;28;01mfor\u001B[39;00m i, k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[43mexamples\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m)}\n\u001B[1;32m     73\u001B[0m features_per_example \u001B[38;5;241m=\u001B[39m collections\u001B[38;5;241m.\u001B[39mdefaultdict(\u001B[38;5;28mlist\u001B[39m)\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, feature \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(features):\n",
      "\u001B[0;31mTypeError\u001B[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# 特定目标的容器，以提供Python的内置通用容器dict、list、set、tuple的替代选择\n",
    "import collections\n",
    "# 与时间相关的功能\n",
    "import time\n",
    "# 使用JSON数据\n",
    "import json\n",
    "# PaddlePaddle深度学习平台\n",
    "import paddle\n",
    "# 用于评估squad（Question Answering）任务性能的函数\n",
    "from paddlenlp.metrics.squad import squad_evaluate, compute_prediction\n",
    "\n",
    "model=model\n",
    "data_loader=dev_data_loader\n",
    "is_test=False\n",
    "\n",
    "# 将模型设置为评估模式，关闭Dropout和BatchNorm等\n",
    "model.eval()\n",
    "\n",
    "# 初始化start和end位置的预测结果列表\n",
    "all_start_logits = []\n",
    "all_end_logits = []\n",
    "# 获取当前时间，用于计算每1000个样本的处理时间\n",
    "tic_eval = time.time()\n",
    "\n",
    "# 遍历数据集中的每个batch\n",
    "for batch in data_loader:\n",
    "    # 从batch中提取input_ids和token_type_ids\n",
    "    input_ids, token_type_ids = batch\n",
    "    # 将input_ids和token_type_ids输入模型，获取开始和结束位置的预测结果\n",
    "    start_logits_tensor, end_logits_tensor = model(input_ids, token_type_ids)\n",
    "\n",
    "    # 遍历每个样本的预测结果\n",
    "    for idx in range(start_logits_tensor.shape[0]):\n",
    "        # 每处理1000个样本，打印处理进度和处理时间\n",
    "        if len(all_start_logits) % 1000 == 0 and len(all_start_logits):\n",
    "            print(\"Processing example: %d\" % len(all_start_logits))\n",
    "            print('time per 1000:', time.time() - tic_eval)\n",
    "            tic_eval = time.time()\n",
    "\n",
    "        # 将每个样本的预测结果添加到预测结果列表中\n",
    "        all_start_logits.append(start_logits_tensor.numpy()[idx])\n",
    "        all_end_logits.append(end_logits_tensor.numpy()[idx])\n",
    "\n",
    "print(data_loader.dataset.data[0])\n",
    "# 使用预测结果生成最终的答案\n",
    "all_predictions, _, _ = compute_prediction(\n",
    "    data_loader.dataset.data, data_loader.dataset.new_data,\n",
    "    (all_start_logits, all_end_logits), False, 20, 30)\n",
    "\n",
    "# 如果是测试阶段\n",
    "if is_test:\n",
    "    # 将预测结果写入JSON文件中\n",
    "    with open('prediction.json', \"w\", encoding='utf-8') as writer:\n",
    "        writer.write(\n",
    "            json.dumps(\n",
    "                all_predictions, ensure_ascii=False, indent=4) + \"\\n\")\n",
    "else:\n",
    "    # 如果不是测试阶段，则对预测结果进行评估\n",
    "    squad_evaluate(\n",
    "        examples=data_loader.dataset.data,\n",
    "        preds=all_predictions,\n",
    "        is_whitespace_splited=False)\n",
    "\n",
    "# 打印前5个问题和预测的答案\n",
    "count = 0\n",
    "for example in data_loader.dataset.data:\n",
    "    count += 1\n",
    "    print()\n",
    "    print('问题：', example['question'])\n",
    "    print('原文：', ''.join(example['context']))\n",
    "    print('答案：', all_predictions[example['id']])\n",
    "    if count >= 5:\n",
    "        break\n",
    "\n",
    "# 将模型设置回训练模式\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
